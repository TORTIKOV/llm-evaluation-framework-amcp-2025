import time
from utils.translator import translate
from utils.censorship_filter import is_censored
from evaluation.evaluate import evaluate_all_metrics
from utils.save_results import save_to_excel

SYSTEM_PROMPT_RU = '''–¢—ã ‚Äî —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å. –ü—Ä–æ—á–∏—Ç–∞–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ –æ—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –Ω–∏–∂–µ –≤–æ–ø—Ä–æ—Å –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ:
1. –£–∫–∞–∂–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏–º–µ–Ω–∞, –¥–µ–π—Å—Ç–≤–∏—è, –º–µ—Å—Ç–∞.
2. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.
3. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∏ –Ω–µ –¥–ª–∏–Ω–Ω–µ–µ 20 —Å–ª–æ–≤.'''

SYSTEM_PROMPT_EN = '''You are a language model. Read the following text and answer the question below very briefly:
1. Include specific names, actions, and places.
2. Avoid abstract or generic wording.
3. Your answer must be in English and no longer than 20 words.'''


def run_narrativeqa_experiment(model, dataset, task, output_dir):
    results_to_save = []

    for idx, example in enumerate(dataset, start=1):
        print(f"üü° –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ {idx}")
        context_en = example["document"]["summary"]["text"]
        question_en = example["question"]["text"]
        ref_en = example["answers"][0]["text"]

        context_ru = translate(context_en, "en", "ru")
        question_ru = translate(question_en, "en", "ru")
        ref_ru = translate(ref_en, "en", "ru")

        try:
            ans_ru_doc_ru, t1 = model.generate(f"{context_ru}\n\n–í–æ–ø—Ä–æ—Å: {question_ru}\n\n–û—Ç–≤–µ—Ç:", SYSTEM_PROMPT_RU)
            ans_ru_doc_en, t2 = model.generate(f"{context_en}\n\n–í–æ–ø—Ä–æ—Å: {question_en}\n\n–û—Ç–≤–µ—Ç:", SYSTEM_PROMPT_RU)
            ans_en_doc_ru, t3 = model.generate(f"{context_ru}\n\nQuestion: {question_ru}\n\nAnswer:", SYSTEM_PROMPT_EN)
            ans_en_doc_en, t4 = model.generate(f"{context_en}\n\nQuestion: {question_en}\n\nAnswer:", SYSTEM_PROMPT_EN)
        except Exception as e:
            print(f"‚ùó –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            continue

        if any(is_censored(ans) for ans in [ans_ru_doc_ru, ans_ru_doc_en, ans_en_doc_ru, ans_en_doc_en]):
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –∏–∑-–∑–∞ —Ü–µ–Ω–∑—É—Ä—ã.")
            continue

        ans_ru_doc_ru_en = translate(ans_ru_doc_ru, "ru", "en")
        ans_ru_doc_en_en = translate(ans_ru_doc_en, "ru", "en")
        ans_en_doc_ru_ru = translate(ans_en_doc_ru, "en", "ru")
        ans_en_doc_en_ru = translate(ans_en_doc_en, "en", "ru")

        result = {
            "Context (EN)": context_en,
            "Question (EN)": question_en,
            "Reference Answer (EN)": ref_en,
            "Reference Answer (RU)": ref_ru,

            "Answer RU‚ÜíRU": ans_ru_doc_ru,
            "Answer EN‚ÜíRU": ans_ru_doc_en,
            "Answer RU‚ÜíEN": ans_en_doc_ru,
            "Answer EN‚ÜíEN": ans_en_doc_en,

            "RU‚ÜíRU‚ÜíEN": ans_ru_doc_ru_en,
            "EN‚ÜíRU‚ÜíEN": ans_ru_doc_en_en,
            "RU‚ÜíEN‚ÜíRU": ans_en_doc_ru_ru,
            "EN‚ÜíEN‚ÜíRU": ans_en_doc_en_ru,

            "Time RU‚ÜíRU": round(t1, 2),
            "Time EN‚ÜíRU": round(t2, 2),
            "Time RU‚ÜíEN": round(t3, 2),
            "Time EN‚ÜíEN": round(t4, 2),
        }

        for key, answer, ref, lang in [
            ("RU‚ÜíRU", ans_ru_doc_ru, ref_ru, "ru"),
            ("EN‚ÜíRU", ans_ru_doc_en, ref_ru, "ru"),
            ("RU‚ÜíEN", ans_en_doc_ru, ref_en, "en"),
            ("EN‚ÜíEN", ans_en_doc_en, ref_en, "en"),
        ]:
            metrics = evaluate_all_metrics(answer, ref, lang=lang, w=0.7)

            result.update({
                f"{key} ROUGE-1": metrics.get("ROUGE-1"),
                f"{key} ROUGE-L": metrics.get("ROUGE-L"),
                f"{key} METEOR": metrics.get("METEOR"),
                f"{key} BERTScore": metrics.get("BERTScore"),
                f"{key} SCI": metrics.get("SCI"),
                f"{key} SCI Overlap": metrics.get("SCI_Overlap"),
                f"{key} SCI IntentScore": metrics.get("SCI_IntentScore"),
                f"{key} SCI Penalty": metrics.get("SCI_Penalty"),
                f"{key} SCI Compression": metrics.get("SCI_Compression"),
                f"{key} SCI Œî": metrics.get("SCI_Delta"),
            })

            for w_val in [0.25, 0.5, 0.75, 0.9]:
                try:
                    sci_w = evaluate_all_metrics(answer, ref, lang=lang, w=w_val)["SCI"]
                    result[f"{key} SCI (w={w_val})"] = sci_w
                except Exception as e:
                    print(f"‚ö†Ô∏è SCI @ w={w_val}: {e}")
                    result[f"{key} SCI (w={w_val})"] = None

        results_to_save.append(result)
        time.sleep(1.5)

    save_to_excel(results_to_save, f"{output_dir}/results_{task}.xlsx")
