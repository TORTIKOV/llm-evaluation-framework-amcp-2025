import time
from utils.translator import translate
from utils.censorship_filter import is_censored
from evaluation.evaluate import evaluate_all_metrics
from utils.save_results import save_to_excel

SYSTEM_PROMPT_RU = '''–¢—ã ‚Äî —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫ –≤ –¥–∏–∞–ª–æ–≥–µ. –ü—Ä–æ—á–∏—Ç–∞–π –∏—Å—Ç–æ—Ä–∏—é –∏ –ø—Ä–æ–¥–æ–ª–∂–∏ –µ—ë –æ–¥–Ω–æ–π —Ä–µ–ø–ª–∏–∫–æ–π:
1. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–æ–≥–∏—á–Ω—ã–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ä–µ–ø–ª–∏–∫.
2. –°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.
3. –ù–µ –ø–∏—à–∏ –±–æ–ª–µ–µ 20 —Å–ª–æ–≤.
–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.'''

SYSTEM_PROMPT_EN = '''You are a dialogue agent. Read the previous turns and respond with one short message:
1. Your reply should logically follow the conversation.
2. Preserve key facts and context.
3. Use no more than 20 words.
The answer must be in English.'''


def run_dialogue_experiment(model, dataset, task, output_dir):
    results_to_save = []

    for idx, example in enumerate(dataset, start=1):
        dialog = example["dialog"]
        if len(dialog) < 3:
            continue

        print(f"üü° –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–∞ {idx}")
        doc_en = " ".join(dialog[:-1])
        ref_en = dialog[-1]

        doc_ru = translate(doc_en, "en", "ru")
        ref_ru = translate(ref_en, "en", "ru")

        if not doc_ru or not ref_ru:
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –∏–∑-–∑–∞ –Ω–µ—É–¥–∞—á–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞.")
            continue

        try:
            ans_ru_doc_ru, t1 = model.generate(doc_ru + "\n\n–û—Ç–≤–µ—Ç:", SYSTEM_PROMPT_RU)
            ans_ru_doc_en, t2 = model.generate(doc_en + "\n\n–û—Ç–≤–µ—Ç:", SYSTEM_PROMPT_RU)
            ans_en_doc_ru, t3 = model.generate(doc_ru + "\n\nAnswer:", SYSTEM_PROMPT_EN)
            ans_en_doc_en, t4 = model.generate(doc_en + "\n\nAnswer:", SYSTEM_PROMPT_EN)
        except Exception as e:
            print(f"‚ùó –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            continue

        if any(is_censored(ans) for ans in [ans_ru_doc_ru, ans_ru_doc_en, ans_en_doc_ru, ans_en_doc_en]):
            print("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω –∏–∑-–∑–∞ —Ü–µ–Ω–∑—É—Ä—ã.")
            continue

        ans_ru_doc_ru_en = translate(ans_ru_doc_ru, "ru", "en")
        ans_ru_doc_en_en = translate(ans_ru_doc_en, "ru", "en")
        ans_en_doc_ru_ru = translate(ans_en_doc_ru, "en", "ru")
        ans_en_doc_en_ru = translate(ans_en_doc_en, "en", "ru")

        result = {
            "Context (EN)": doc_en,
            "Reference Reply (EN)": ref_en,
            "Reference Reply (RU)": ref_ru,

            "Answer RU‚ÜíRU": ans_ru_doc_ru,
            "Answer EN‚ÜíRU": ans_ru_doc_en,
            "Answer RU‚ÜíEN": ans_en_doc_ru,
            "Answer EN‚ÜíEN": ans_en_doc_en,

            "RU‚ÜíRU‚ÜíEN": ans_ru_doc_ru_en,
            "EN‚ÜíRU‚ÜíEN": ans_ru_doc_en_en,
            "RU‚ÜíEN‚ÜíRU": ans_en_doc_ru_ru,
            "EN‚ÜíEN‚ÜíRU": ans_en_doc_en_ru,

            "Time RU‚ÜíRU": round(t1, 2),
            "Time EN‚ÜíRU": round(t2, 2),
            "Time RU‚ÜíEN": round(t3, 2),
            "Time EN‚ÜíEN": round(t4, 2),
        }

        for key, answer, ref, lang in [
            ("RU‚ÜíRU", ans_ru_doc_ru, ref_ru, "ru"),
            ("EN‚ÜíRU", ans_ru_doc_en, ref_ru, "ru"),
            ("RU‚ÜíEN", ans_en_doc_ru, ref_en, "en"),
            ("EN‚ÜíEN", ans_en_doc_en, ref_en, "en"),
        ]:
            metrics = evaluate_all_metrics(prediction=answer, reference=ref, lang=lang, w=0.7)

            result.update({
                f"{key} ROUGE-1": metrics.get("ROUGE-1"),
                f"{key} ROUGE-L": metrics.get("ROUGE-L"),
                f"{key} METEOR": metrics.get("METEOR"),
                f"{key} BERTScore": metrics.get("BERTScore"),
                f"{key} SCI": metrics.get("SCI"),
                f"{key} SCI Overlap": metrics.get("SCI_Overlap"),
                f"{key} SCI IntentScore": metrics.get("SCI_IntentScore"),
                f"{key} SCI Penalty": metrics.get("SCI_Penalty"),
                f"{key} SCI Compression": metrics.get("SCI_Compression"),
                f"{key} SCI Œî": metrics.get("SCI_Delta"),
            })

            for w_val in [0.25, 0.5, 0.75, 0.9]:
                try:
                    sci_w = evaluate_all_metrics(prediction=answer, reference=ref, lang=lang, w=w_val)["SCI"]
                    result[f"{key} SCI (w={w_val})"] = sci_w
                except Exception as e:
                    print(f"‚ö†Ô∏è SCI @ w={w_val}: {e}")
                    result[f"{key} SCI (w={w_val})"] = None

        results_to_save.append(result)
        time.sleep(1.5)

    save_to_excel(results_to_save, f"{output_dir}/results_{task}.xlsx")
